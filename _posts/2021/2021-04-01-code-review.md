---
layout:     post
title:      "[코드리뷰]TTS 시스템"
subtitle:   "개인화 TTS 시스템 만들기"
mathjax: true
tags:
  - Text-to-Speech
  - Speech Synthesis
  - Deep Learning
---

# [코드리뷰] - TTS 시스템

최근 몇년간 TTS(Text to Speech)는 빠르게 발전하여 이제는 복잡한 작업 절차 없이 데이터를 이용하여 텍스트로부터 고품질의 음성을 생성할 수 있는 방법론이 개발되었습니다.
방법론 뿐만 아니라 코드와 데이터까지 Github, Kaggle 등과 같은 <u>공개저장소에 공개</u>되면서 이제는 **개발과정조차 간소화**되어 진정한 의미로 개인화 TTS를 개발할 수 있는 환경이 구축되었습니다.

![](/img/in-post/2021/2021-04-01/clova_voice_example.gif)
<center><b>네이버 TTS 시스템<a href="https://clova.ai/voice">(출처 : Clova Voice)</a></b></center>

하지만 딥러닝에 대해 잘 아는 사람들도 음성이라는 낯선 도메인 때문에 쉽게 접근하지 못하여 TTS 시스템을 개발하지 못하는 것이 현실입니다.
따라서 오늘 포스팅에서는 Tacotron2와 WaveGlow를 이용하여 <u>간단하게 개인화 <b>한글 TTS</b>를 개발하는 파이프 라인</u>을 설명드리도록 하겠습니다.

이글은 2018년 ICASSP 2018에서 공개된 **[Tacotron2](https://arxiv.org/abs/1712.05884v2) 논문의 구현체**를 기반으로 개인화 시스템을 만드는 방법에 대해 설명드리려고 합니다.
현재 기준으로 더 고도화 된 TTS논문들이 공개되었기 때문에 해당 논문들에 비하면 성능(음성 품질)이 떨어지고, 많은 데이터를 필요로 합니다.
따라서 좀 더 고품질의 음성 및 실제 활용화 할 수 있는 시스템을 원하시는 분들의 눈높이에 맞지 않을 수 있습니다.

이 글은 개인적인 의견을 담고 있기 때문에 **실제 내용과 다를 수** 있습니다.
또한 딥러닝 아키텍처에 대해 이해하고 python 프로그래밍 경험이 있는 분들은 대상으로 작성되었습니다.
 
글에서 사용한 코드 및 데이터는 아래 Reference Link를 참조하시기 바랍니다.

#### Short Summary
개인화 TTS 시스템을 만드는 과정을 크게 나누면 아래와 같습니다.

1. 데이터 수집
2. 음성 데이터 전처리
3. Tacotron2 모델 개발
4. WaveGlow 모델 개발

## 1. 데이터 수집
모델을 학습하는데 필요한 <u>데이터(음성, 스크립트)를 수집하는 단계</u>입니다.
데이터는 개인의 음성과, 음성의 발화 내용이 적혀있는 스크립트로 이루어져 있어야 합니다.
음성데이터는 **개인의 음성**을 녹음한 음성파일(.wav, .pcm, .raw, .mp3) 등을 의미합니다.
스크립트는 음성의 발화 내용이 적혀있는 .txt 파일을 의미합니다.

![](/img/in-post/2021/2021-04-01/dataset_example.png)
<center><b>데이터 예시</b></center>

데이터를 수집하는 방법에는 다양한 형태가 있을 수 있습니다.
1. 이미 구축된 데이터(음성, 스크립트)를 가져오는 방식
2. 직접 음성을 녹음하고 스크립트를 제작하여 데이터를 만드는 방식
3. 녹음된 음성 클립을 가져와서 스크립트를 제작하여 데이터를 만드는 방식

##### 1.1 구축된 데이터 활용
너무나 당연한 이야기이지만 음성 데이터 안에 Noise가 적을 수록 모델은 음성과 텍스트 사이의 패턴을 잘 파악할 수 있습니다.
따라서 노이즈가 제거된 구축된 데이터를 활용하는 것이 가장 좋은 품질의 음성을 생성할 수 있습니다.
게다가 스크립트 데이터도 함께 주어지는 경우 데이터 수집으로 인해 발생하는 <u>고된 전처리 작업을 피할 수 있는 장점</u>을 갖고 있습니다.

외부에 공개된 TTS 데이터로는 [LJ speech dataset(English)](https://keithito.com/LJ-Speech-Dataset/), [VCTK dataset (English)](https://datashare.ed.ac.uk/handle/10283/3443), [KSS dataset (Korean)](https://www.kaggle.com/bryanpark/korean-single-speaker-speech-dataset) 등이 있습니다.
특히 KSS 데이터는 전문 여성 성우 1명의 음성으로 제작된 데이터로써, 품질이 매우 좋고 약 12시간 분량의 풍부한 음성파일로 구성되어 있습니다. 

![](/img/in-post/2021/2021-04-01/kss_dataset.png)
<center><b>KSS 데이터 예시</b></center>

##### 1.2 직접 음성을 제작
개인화 TTS를 개발하는 대부분의 사람들은 본인의 음성 또는 지인의 음성으로 개발하기를 원하기 때문에 직접 음성을 제작하는 경우가 대부분입니다.
따라서 직접 음성을 제작하는 경우가 많은데 이는 노이즈가 없는 환경에서 음성을 제작할 수 있기 때문에 좋은 품질의 음성모델을 구축할 수 있습니다.

음성을 제작할 떄 음성을 녹음하고 스크립트를 만드는 방식도 좋지만 개인적으로 스크립트를 먼저 제작하고 음성을 녹음하는 방식이 더 효율적입니다.
스크립트를 따로 만드는 것보다 이미 구축된 스크립트(일정 길이의 문장)를 사용하는 것이 효율적이므로 외부 서적, KSS 데이터의 스크립트 등을 활용하여 제작하는 것을 추천드립니다.

<span style="color:#FF0800"><b>주의할 점</b></span>은 스크립트에 **다양한 형태**(평서문, 의문문, 명령문, 감탄문 등)의 문장이 포함되어 있어야합니다.
만일 평서문(일반적으로 ~~합니다.로 끝나는 문장)으로만 스크립트를 구성할 경우 모델은 명령문(일반적으로 ~~해. 로 끝나는 문장)을 재대로 발화하지 못하는 현상이 발생할 수 있습니다.

![](/img/in-post/2021/2021-04-01/recording_example.png)
<center><b>음성 데이터 녹음 예시</b></center>

##### 1.3 녹음된 음성으로 데이터 제작
외부 녹음된 음성 클립으로 데이터를 제작하는 것은 사실상 매우 어려운 일입니다.
일단 녹음된 음성에 다양한 배경음악, 환경소음이 포함되어 있는 경우가 대부분이기 때문에 음성의 품질이 좋지 않습니다.
또한 녹음된 음성에 맞는 스크립트를 제작하는 것이 생각보다 고된 작업이기 때문입니다.
하지만 해당 작업을 통해 음성을 제작하고 싶다면 음성편집 및 스크립트 자동생성과 관련된 몇가지 Tool을 추천드립니다.

[**[1] Audacity : 음성 편집기(무료)**](https://www.audacityteam.org/)  
Audacity는 무료 음성 편집기 중 하나입니다. 간단하게 **음성을 자를 수** 있도록 편의성 있는 UI를 제공하기 때문에 간편하게 사용할 수 있습니다.
또한 데이터 전처리과정에서 필요한 배경 노이즈를 제거하는 기능을 포함하고 있으므로 활용성이 높습니다. 
개인적인 의견을 덧붙이자면 여러개의 음성을 한꺼번에 작업(환경 소음 제거)할 수 있는 것이 이 프로그램의 가장 큰 장점입니다.

![](/img/in-post/2021/2021-04-01/audacity_example.png)
<center><b>Audacity 사용 화면 예시</b></center>


[**[2] Clova Speech : 자막 생성기(유료)**](https://clova.ai/speech)  
Clova에서 제공하는 자막 생성기입니다. 음성파일을 듣고 직접 스크립트를 생성하는 것은 많은 시간이 소요될 뿐만 아니라 고된 작업입니다. 
Clova에서 제공하는 자막 생성기를 활용하면 비교적 빠른 시간 안에 음성에 맞는 자막을 생성할 수 있습니다.
또한 음성이 발화된 시간대를 표기하게 제공하므로 음성을 자르고 스크립트를 구성하는 작업이 빨라 질 수 있습니다.
생성된 자막품질은 대부분 우수하나 틀린 스크립트가 존재 할 수 있으므로 더 좋은 모델을 만들기 위해서는 검수과정이 필요할 수 있습니다.
게다가 유로 프로그램이기 때문에 생각보다 많은 비용이 필요할 수 있습니다.

![](/img/in-post/2021/2021-04-01/clova_speech_example.png)
<center><b>Clova Speech 사용 화면 예시</b></center>


[**[3] VREW : 자막 생성기(부분무료)**](https://vrew.voyagerx.com/ko/)  
VREW는 보이저엑스(voyagerX) 인공지능 스타트업에서 만든 자막생성 프로그램입니다. 
영상데이터서 음성자막을 추출할 수 있는 기능을 제공하며, 영상과 자막의 싱크를 맞출 수 있도록 편의성 있는 UI를 제공합니다.
영상데이터에서 음성과 스크립트를 생성해야 한다면 해당 프로그램을 활용하는 것이 데이터 제작 시간을 단축하는데 큰 역할을 할 수 있습니다.
다만 2021년 기준으로 매월 90분 정도 음성인식 기능을 무료로 제공한다고 하니, 긴 데이터 제작이 필요하다면 유로결제가 필요할 수 있습니다.

![](/img/in-post/2021/2021-04-01/vrew_example.png)
<center><b>VREW 사용 화면 예시</b></center>

[**[4] ESPnet(한글) : 음성 인식 API(무료)**](https://github.com/hchung12/espnet-asr)  
ESPnet은 음성인식 모델을 개발할 수 있도록 과련 개발 모델 및 파이프라인을 잘 정리한 오픈소스입니다.
최근 [ETRI](https://www.etri.re.kr/intro.html) 에서 1000시간 분량의 [한국어 음성 데이터](https://aihub.or.kr/aidata/105) 와 Espenet 오픈소스를 활용하여 모델을 만들고 학습 Checkpoint와 사용방법(Tutorial)을 공개하였습니다.
이 프로그램을 활용하면 무료로 음성으로부터 스크립트를 생성할 수 있습니다.
다만 프로그램을 활용하려면 Pytorch 및 Python 프로그래밍 능력이 필요하며, 스크립트 생성 품질이 유료 프로그램보다 떨어질 수 있습니다.
게다가 긴 길이의 음성은 직접 잘라서 프로그램에 넣어줘야 하는 불편함이 있으므로, 빠르게 데이터 생성 작업이 필요하다면 좋은 선택이 아닐 수 있습니다.

##### 1.4 데이터 수집(예시)
저는 제 음성을 발화할 수 있는 TTS 시스템을 만들기 위하여 직접 녹음하여 데이터를 구축하였습니다.
먼저 [KSS 데이터](https://www.kaggle.com/bryanpark/korean-single-speaker-speech-dataset) 에 포함되어 있는 스크립트를 활용하기 위하여 데이터를 다운받았습니다.

![](/img/in-post/2021/2021-04-01/kss_script_example.png)
<center><b>KSS 스크립트 예시</b></center>

그리고 그 스크립트를 그대로 읽어서 핸드폰 녹음기를 활용하여 약 3000개의 음성 데이터(약 100분)를 생성하였습니다.

![](/img/in-post/2021/2021-04-01/real_recording_example.png)
<center><b>데이터 수집 예시</b></center>


## 2. 음성 데이터 전처리
음성 데이터에서 <u>배경소음을 제거</u>하고 모델이 잘 인식할 수 있도록 <u>불필요한 음성을 자르는 작업</u>입니다.
데이터 수집단계에서 스크립트 생성과 관련된 작업 및 프로그램을 설명하였기 때문에 음성과 관련된 전처리 작업만 설명드리겠습니다.

![](/img/in-post/2021/2021-04-01/preprocess_pipeline.png)
<center><b>데이터 전처리 파이프라인</b></center>

##### 2.1 잡음 제거
만약 음성을 직접 녹음하였다면 방음이나 차음이 잘 되어있는 환경에서도 백색 소음 또는 잡음이 포함되어 있을 수 있습니다.
또한 외부 녹음된 음성 클립을 추출한 경우에는 거의 **대부분 소음이 포함**되어 있습니다.

이러한 소음을 제거하지 않고 모델을 학습하면 모델이 잘 수렴하지 않을 수 있으며, 학습된 모델에서 발화된 음성 뿐만아니라 듣기 싫은 음성이 포함될 수 있습니다.
따라서 목표로 하는 음성을 제외한 **잡음을 제거하는 작업**이 <u>반드시 필요</u>합니다.

![](/img/in-post/2021/2021-04-01/preprocess_important.png)
<center><b>전처리가 필요한 이유</b></center>

잡음을 제거하기 위하여 사용할 수 있는 대표적인 프로그램으로 2가지 정도를 살펴보겠습니다.

[**[1] Adobe Audtion : 오디오 편집기(유료)**](https://helpx.adobe.com/kr/audition/how-to/remove-noise-audio-files.html)   
오디오 편집기 중 가장 유명한 Adobe 프로그램입니다.
유투브([잡음 제거 영상](https://www.youtube.com/watch?v=IId5KbsIaIA)) 및 블로그([어도비 오디션 강좌](https://m.blog.naver.com/PostView.nhn?blogId=fadme&logNo=220826663281&proxyReferer=https:%2F%2Fwww.google.com%2F)) 등 다양한 곳에서 튜토리얼을 제공하고 있기 때문에 간편하게 음성 데이터에서 노이즈를 제거하는 방법을 배울 수 있습니다.
해당 프로그램을 이용하면 잡음 제거 뿐만 아니라 음성 보정(깨끗하고 선명하게)도 가능합니다. 다만 유료 프로그램이라는 단점을 갖고 있습니다.

![](/img/in-post/2021/2021-04-01/audition_example.png)
<center><b>Adobe Audition 프로그램</b></center>

[**[2] Audacity : 음성 편집기(무료)**](https://www.audacityteam.org/)  
음성 수집단계에서도 언급했던 Audacity는 유용한 무료 음성 편집기 입니다. 
해당 편집기의 가장 큰 장점은 여러개의 음성을 한꺼번에 작업할 수 있다는 점 입니다.
일반적으로 음성을 동일한 환경에서 직접 생성하였다면 잡음의 패턴도 비슷하기 때문에 한꺼번에 작업(잡음제거)하는 것이 전처리 시간을 단축할 수 있습니다.

###### 2.1 잡음 제거(예시)
Audacity 프로그램을 활용하여 잡음 제거 하는 예시입니다.
Audacity(한글버전)을 설치한 후 메뉴에서 파일(F)->가져오기(I)->오디오(A)를 순서대로 클릭하여 여러개의 오디오파일을 한꺼번에 불러옵니다.

![](/img/in-post/2021/2021-04-01/audacity_load.gif)
<center><b>audacity 데이터 불러오기 예시</b></center> 


